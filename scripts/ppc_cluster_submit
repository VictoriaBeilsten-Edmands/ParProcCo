#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import argparse
import logging
import os
from typing import List

from ParProcCo.job_controller import JobController
from ParProcCo.passthru_wrapper import PassThruWrapper

def create_parser():
    '''
     $ ppc_cluster_submit program [--output cluster_output_dir] [--jobs 4] --cores 6 --memory 4G -s 0.01 ... [input files]
     '''
    parser = argparse.ArgumentParser(description='ParProcCo run script')
    parser.add_argument('-o', '--output', help='str: cluster output file or directory')
    parser.add_argument('--jobs', help='int: number of cluster jobs to split processing into', type=int, default=1)
    parser.add_argument('--memory', help='str: memory to use per cluster job', required=True)
    parser.add_argument('--cores', help='int: number of cores to use per cluster job', type=int, required=True)
    parser.add_argument('-D', '--debug', help='show debugging information', action='store_true')
    return parser

def run_ppc(args: argparse.Namespace, script_args: List) -> None:
    '''
    Run JobController
    '''
    from ParProcCo.utils import load_cfg
    cfg = load_cfg()

    project = os.getenv(cfg.project_env_var)
    if not project:
        raise ValueError(f'{cfg.project_env_var} environment variable not defined')
    cluster_name = os.getenv('SGE_CELL')
    if not cluster_name: # Module load global/cluster or hamilton
        raise ValueError(f'SGE_CELL environment variable not defined. {cfg.cluster_help_msg}')
    if cluster_name not in cfg.clusters:
        raise ValueError(f'SGE_CELL value not known {cfg.clusters.keys()})')
        
    cluster = cfg.clusters[cluster_name]
    cluster_resources = cluster.resources
    cluster_queue = cluster.default_queue
    if cluster.user_queues:
        from getpass import getuser
        user = getuser()
        if cluster.user_queues:
            for q,us in cluster.user_queues.items():
                if user in us:
                    cluster_queue = q
                    logging.debug('User is %s so using cluster queue %s', user, cluster_queue)
                    break

    logging.info('Running for project %s on cluster %s in queue %s with resources %s', project, cluster, cluster_queue, cluster_resources)
    program = script_args[0]
    if args.jobs == 1:
        wrapper = PassThruWrapper()
    elif args.jobs > 1:
        allowed = cfg.allowed_programs
        if program not in allowed:
            raise ValueError(f'{program} not on allowed list in {cfg}')

        import importlib
        try:
            package = allowed[program]
            wrapper_module = importlib.import_module(f'{package}.{program}_wrapper')
        except Exception as exc:
            raise ValueError(f'Cannot import {program}_wrapper as a Python module from package {package}') from exc
        try:
            wrapper = wrapper_module.Wrapper()
        except Exception as exc:
            raise ValueError(f'Cannot create Wrapper from {program}_wrapper module') from exc
    else:
        raise ValueError(f'Number of jobs must be one or more, given {args.jobs}')
    wrapper.set_module(cluster.module)
    wrapper.set_cores(args.cores)
    output = wrapper.get_output(args.output, script_args[1:])
    jc = JobController(wrapper, output, project, cluster_queue, cluster_resources)
    jc.run(args.jobs, script_args, args.memory, "PPC-" + program)
    print("complete")

if __name__ == '__main__':
    args, script_args = create_parser().parse_known_args()
    logging.getLogger().setLevel(logging.DEBUG if args.debug else logging.INFO)
    run_ppc(args, script_args)
